getwd()
######### 随机森林-分类问题#########
install.packages("randomForest")
library(randomForest)
rfNews()
data(iris)
library(caret)
set.seed(123) # 设置随机数种子，以便结果可重复
trainIndex <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]
#2.划分训练集和测试集
library(ggplot2)
library(caret)
set.seed(123) # 设置随机数种子，以便结果可重复
trainIndex <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]
library(lattice)
library(ggplot2)
library(lattice)
library(caret)
set.seed(123) # 设置随机数种子，以便结果可重复
trainIndex <- createDataPartition(iris$Species, p = 0.7, list = FALSE)
trainData <- iris[trainIndex, ]
testData <- iris[-trainIndex, ]
set.seed(123)
rf_model <- randomForest(Species ~ ., data = trainData)
pred <- predict(rf_model, testData)
# 计算混淆矩阵
conf_matrix <- table(pred, testData$Species)
# 计算准确率
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
# 计算召回率
recall <- diag(conf_matrix) / rowSums(conf_matrix)
# 计算F1值
F1_score <- 2 * (recall * accuracy) / (recall + accuracy)
# 打印结果
cat(paste("Accuracy: ", round(accuracy, 2), "\n"))
cat(paste("Recall: ", round(recall, 2), "\n"))
cat(paste("F1 Score: ", round(F1_score, 2), "\n"))
print(conf_matrix)
？data
?data
?randomforest
?randomForest
?RandomForest
?logit
?logit
?list
## GLM model
data(mtcars)
force(mtcars)
View(trainIndex)
View(mtcars)
mtcars$am <- as.factor(mtcars$am)
## GLM model
data(mtcars)
data(mtcars)
View(mtcars)
mtcars$am <- as.factor(mtcars$am)
model <- glm(am~mpg+hp+wt,data = mtcars, family = binomial(link = "logit"))
model
summary(model)
library(car)
data(Mroz)
force(Mroz)
model <- glm(lfp ~ k5 + age, data = Mroz, family = binomial())
linear_component <- predict(model, type = "link")
plot(Mroz$k5, linear_component, xlab = "Number of children 5 years old or younger (k5)", ylab = "Linear component")
plot(Mroz$age, linear_component, xlab = "Age (years)", ylab = "Linear component")
linear_component_stored <- model$linear.predictors
all.equal(linear_component_observed, linear_component_stored)
linear_component_observed <- predict(model, type = "link")
linear_component_stored <- model$linear.predictors
all.equal(linear_component_observed, linear_component_stored)
# Calculate the predicted probabilities that a person is employed for each observation in the dataset
probabilities <- predict(model, type = "response")
# Print the first 10 predicted probabilities
head(probabilities, 10)
## Task4.
# Calculate the predicted probabilities that a person is employed for each observation in the dataset
probabilities_observed <- predict(model, type = "response")
# Compare the observed values of the predicted probabilities with the values stored in the model object
probabilities_stored <- model$fitted.values
# Check if the two vectors are equal
all.equal(probabilities_observed, probabilities_stored)
# Calculate the predicted probabilities that a person is employed for each observation in the dataset
probabilities <- predict(model, type = "response")
# Create a scatter plot of predicted probabilities versus age
plot(Mroz$age, probabilities, xlab = "Age (years)", ylab = "Predicted probability of employment")
# Create a scatter plot of predicted probabilities versus number of children 5 years old or younger
plot(Mroz$k5, probabilities, xlab = "Number of children 5 years old or younger (k5)", ylab = "Predicted probability of employment")
Mroz$age_k5 <- interaction(Mroz$age, Mroz$k5)
probabilities <- predict(model, newdata = Mroz, type = "response")
plot_data <- data.frame(age = Mroz$age, probabilities = probabilities, k5 = Mroz$k5)
library(ggplot2)
ggplot(plot_data, aes(x = age, y = probabilities, color = factor(k5))) +
geom_line() +
labs(x = "Age (years)", y = "Predicted probability of employment", color = "Number of children 5 years old or younger (k5)")
#########################
library(car)
data("Chile")
force(Chile)
Chile2 <- Chile[which(Chile$vote == "N" | Chile$vote == "Y"), ]
Chile2$vote <- factor(Chile2$vote)
Chile2$vote01 <- recode(Chile2$vote, "'N'=0;'Y'=1", as.factor = F)
Chile2$income_th <- Chile2$income/1000
summary(model1)
model1 <- glm(vote ~ statusquo + income_th + age + sex + region + education, family = "binomial",
data = Chile2)
summary(model1)
library(margins)
install.packages('margins')
library(margins)
M1 <- margins(model1)
M1
summary(M1)
####################
Chile$income_th<-Chile$income/1000
library(nnet)
table(Chile$vote)
table(Chile$vote)
model1<-multinom(vote~statusquo+income_th+age,data=Chile)
model1
table(Chile$vote)
summary(model1)
install.packages("carData")
library(car)
library(effects)
# Task 1
fit <- glm(lfp ~ k5 + age + inc, data = Mroz, family = binomial)
summary(fit)
# Task 2
eff <- effect("k5", fit, xlevels = list(k5 = c(0,1,3)))
install.packages("carData")
library(car)
library(effects)
install.packages("carData")
data(Mroz)
library(car)
library(effects)
library(ggplot2)
data("Mroz")
# Model 1
model1 <- glm(lfp ~ k5 + age + inc, data = Mroz, family = binomial(link = "logit"))
summary(model1)
exp(coef(model1))
#Task 2
age_mean <- mean(Mroz$age)
inc_mean <- mean(Mroz$inc)
newdata <- data.frame(k5 = seq(min(Mroz$k5), max(Mroz$k5), length.out = 100),
age = age_mean,
inc = inc_mean)
prob <- predict(model1, newdata, type = "response")
effect_plot <- plot(effect("k5", model1), xlab = "k5", ylab = "Probability of being employed")
plot(effect("k5", model1), effect_plot, rug = FALSE)
#Task 1
library(car)
data(Mroz)
# Model 1:
model1 <- glm(lfp ~ k5 + age + inc, data = Mroz, family = binomial(link = "logit"))
summary(model1)
# Interpret coefficients using odds ratios
exp(coef(model1))
library(effects)
# calculate predicted probabilities of being employed
pred_prob <- effect("k5", model1, xlevels = list(k5 = c(0, 1)))
# plot k5 against predicted probabilities of being employed
plot(pred_prob, ylim = c(0, 1), xlab = "k5", ylab = "Probability of employment")
library(ggplot2)
# calculate predicted probabilities of being employed for different levels of k5
pred_prob_min <- predict(model1, newdata = data.frame(k5 = 0, age = min(Mroz$age), inc = min(Mroz$inc)), type = "response")
pred_prob_mean <- predict(model1, newdata = data.frame(k5 = 0, age = mean(Mroz$age), inc = mean(Mroz$inc)), type = "response")
pred_prob_max <- predict(model1, newdata = data.frame(k5 = 0, age = max(Mroz$age), inc = max(Mroz$inc)), type = "response")
k5_values <- c(0,1)
df <- data.frame(k5_values,
pred_prob_min,
pred_prob_mean,
pred_prob_max)
# plot k5 against predicted probabilities of being employed for three situations described above.
ggplot(df, aes(x = k5_values)) +
geom_line(aes(y = pred_prob_min, color = "Minimum"), size = 1) +
geom_line(aes(y = pred_prob_mean, color = "Mean"), size = 1) +
geom_line(aes(y = pred_prob_max, color = "Maximum"), size = 1) +
xlab("k5") +
ylab("Probability of Employment") +
ggtitle("Predicted Probabilities for Different k5 values")
# calculate predicted probabilities of being employed for different levels of family income (inc)
pred_prob_inc <- effect("inc", model1, xlevels = list(inc = seq(min(Mroz$inc), max(Mroz$inc), length.out = 100)))
# plot income against predicted probabilities of being employed
plot(pred_prob_inc, ylim = c(0, 1), xlab = "Family Income", ylab = "Probability of employment")
# Calculate mean of predicted probabilities of the observed dataset
mean_prob_observed <- mean(predict(model1, type = "response"))
# Calculate predicted probabilities of being employed when family income of all women in the study increase by 5
mean_prob_new_income <- mean(predict(model1, newdata = data.frame(k5 = mean(Mroz$k5), age = mean(Mroz$age), inc = mean(Mroz$inc)+5), type = "response"))
# Compare mean of predicted probabilities
mean_diff <- mean_prob_new_income - mean_prob_observed
mean_diff
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
install.packages("MASS")
library(MASS)
data("Pima.tr")
force(Pima.tr)
View(Pima)
logit_model <- glm(type~.,family=binomial(link = "logit"),data = Pima.tr)
logit_model
logit_model
probit_model <- glm(type~.,family = binomial(link = "probit"),data = Pima.tr)
probit_model
summary(probit_model)
summary(logit_model)
# 导入所需库
library(dplyr)
library(tidyr)
library(caret)
library(e1071)
library(ROSE)
install.packages("ROSE")
library(ROSE)
library(MLmetrics)
install.packages("MLmetrics")
library(MLmetrics)
# 加载 childhood 数据集
childhood <- read.csv("C:/Users/x/Downloads/EU.csv")
childhood
X <- childhood[, -ncol(childhood)]
y <- childhood[, ncol(childhood)]
y
# 处理不平衡类问题
set.seed(42)
over_sampling <- ROSE::ovun.sample(y ~ ., data = cbind(X, y), method = "over", N = 2*sum(y==0), seed = 42)
X_resampled <- over_sampling$data[, -ncol(over_sampling$data)]
y_resampled <- over_sampling$data[, ncol(over_sampling$data)]
# 划分数据集
set.seed(42)
train_index <- createDataPartition(y_resampled, p = 0.7, list = FALSE, times = 1)
X_train <- X_resampled[train_index, ]
y_train <- y_resampled[train_index]
X_test <- X_resampled[-train_index, ]
y_test <- y_resampled[-train_index]
# 特征选择
skb <- caret::nearZeroVar(X_train, names = TRUE)
X_train <- X_train[, -skb]
X_train <- X_train[, !skb, drop = FALSE]
if(length(skb) > 0){
X_train <- X_train[, !skb, drop = FALSE]
}
skb <- caret::nearZeroVar(X_train, names = TRUE)
if(length(skb) > 0){
X_train <- X_train[, !skb, drop = FALSE]
}
# 特征选择
skb <- caret::nearZeroVar(X_train, names = TRUE)
if(length(skb) > 0){
X_train <- X_train[, !skb, drop = FALSE]
}
# 特征选择
skb <- caret::nearZeroVar(X_train, names = TRUE)
if(length(skb) > 0){
skb <- as.logical(skb)
X_train <- X_train[, !skb, drop = FALSE]
}
# 特征选择
skb <- caret::nearZeroVar(X_train, names = TRUE)
if(length(skb) > 0){
skb <- as.logical(skb)
X_train <- X_train[, !skb, drop = FALSE]
} else {
X_train <- X_train
}
install.packages("ggplot2")
install.packages("gridExtra")
# 安装所需的库（如果尚未安装）
install.packages("ggplot2")
install.packages("gridExtra")
# 加载库
library(ggplot2)
library(gridExtra)
# 创建数据框
models <- c("Logistic Regression", "Decision Tree", "Random Forest", "K-Nearest Neighbors", "Naive Bayes", "Support Vector Machine")
AUC <- c(0.695587, 0.856066, 0.883218, 0.852412, 0.687389, 0.762924)
Sensitivity <- c(0.631608, 0.869934, 0.882379, 0.857819, 0.674009, 0.752974)
Specificity <- c(0.652671, 0.695657, 0.710541, 0.668444, 0.601355, 0.662335)
PPV <- c(0.647145, 0.742457, 0.754568, 0.722944, 0.630343, 0.692214)
NPV <- c(0.637241, 0.841349, 0.856932, 0.823368, 0.646525, 0.726663)
Accuracy <- c(0.642095, 0.783167, 0.796826, 0.763535, 0.637837, 0.707847)
df <- data.frame(models, AUC, Sensitivity, Specificity, PPV, NPV, Accuracy)
# 创建一个基本的ggplot对象
p <- ggplot(df, aes(x = models, y = AUC)) +
geom_bar(stat = "identity", fill = "steelblue") +
labs(title = "Model Evaluation Metrics", x = "Models", y = "Value") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, size = 16, face = "bold"),
axis.title = element_text(size = 12, face = "bold"),
axis.text.x = element_text(angle = 45, hjust = 1),
panel.grid.major = element_blank(),
panel.grid.minor = element_blank())
# 绘制其他指标
p_sensitivity <- p %+% aes(x = models, y = Sensitivity)
p_specificity <- p %+% aes(x = models, y = Specificity)
p_PPV <- p %+% aes(x = models, y = PPV)
p_NPV <- p %+% aes(x = models, y = NPV)
p_Accuracy <- p %+% aes(x = models, y = Accuracy)
# 将所有图形排列在一起
grid.arrange(p, p_sensitivity, p_specificity, p_PPV, p_NPV, p_Accuracy, ncol = 2)
# 保存为图片
ggsave("model_evaluation_metrics.png", grid.arrange(p, p_sensitivity, p_specificity, p_PPV, p_NPV, p_Accuracy, ncol = 2), width = 16, height = 10, dpi = 300)
# 创建数据框
models <- c("Logistic Regression", "Decision Tree", "Random Forest", "K-Nearest Neighbors", "Naive Bayes", "Support Vector Machine")
AUC <- c(0.695587, 0.856066, 0.883218, 0.852412, 0.687389, 0.762924)
Sensitivity <- c(0.631608, 0.869934, 0.882379, 0.857819, 0.674009, 0.752974)
Specificity <- c(0.652671, 0.695657, 0.710541, 0.668444, 0.601355, 0.662335)
PPV <- c(0.647145, 0.742457, 0.754568, 0.722944, 0.630343, 0.692214)
NPV <- c(0.637241, 0.841349, 0.856932, 0.823368, 0.646525, 0.726663)
Accuracy <- c(0.642095, 0.783167, 0.796826, 0.763535, 0.637837, 0.707847)
results <- data.frame(models, AUC, Sensitivity, Specificity, PPV, NPV, Accuracy)
# 创建图形
p1 <- ggplot(results, aes
# 加载所需的包
library(maps)
# 加载所需的包
install('maps')
# 加载所需的包
install.packages('maps')
install.packages('ggplot2')
install.packages("ggplot2")
install.packages("ggplot2")
install.packages("ggplot2")
library(maps)
library(ggplot2)
# 从maps包中获取中国地图边界数据
china_map <- map_data("china")
data(china.cities)
china_map <- map_data("china")
library(maps)
data(china.cities)
china_map <- map_data("world", region = "China")
# 绘制中国地图
ggplot() +
geom_polygon(data = china_map, aes(x = long, y = lat, group = group), fill = "white", color = "black") +
coord_fixed() +
theme_void()
# 从rnaturalearth包中获取台湾地图边界数据
taiwan_map <- ne_download(scale = 10, type = "admin_0_boundary_lines_land", category = "cultural", country = "taiwan")
taiwan_map <- ne_download(scale = 10, type = "admin_0_boundary_lines_land", category = "cultural", country = "taiwan")
install.packages("rnaturalearth")
taiwan_map <- ne_download(scale = 10, type = "admin_0_boundary_lines_land", category = "cultural", country = "taiwan")
library(rnaturalearth)
taiwan_map <- ne_download(scale = 10, type = "admin_0_boundary_lines_land", category = "cultural", country = "taiwan")
library(rnaturalearth)
taiwan_map <- ne_download(scale = 10, type = "admin_0_boundary_lines_land", category = "cultural", ISO_A3 = "TWN")
setwd("C:/Users/x/Desktop/论文3-童年逆境与新冠肺炎/双重机器学习 Double Machine Learning/原文和代码-Does noncompliance with COVID-19 regulations impact the depressive symptoms of others/replication files")
getwd()
